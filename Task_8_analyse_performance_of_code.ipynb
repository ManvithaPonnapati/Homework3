{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the Performance of LSTM code using Profiler\n",
    "\n",
    "\n",
    "Note the instructions where not clear on whether we are supposed to improve the performance or just analyse it. I went with just analyzing the performance using the tools mentioned. Not sure why we were asked to use nbocnvert ? Julia notebooks let me convert my code to .jl files directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Read the performance tips "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finished reading the performance tips - Key points that I didn't think of earlier\n",
    "\n",
    "1. Copying isn't always bad \n",
    "2. Accessing arrays in memory order along columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Check for type instabilities. I checked for type instabilities by running @code_warntype on one epoch of the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYSIS : Based on the example in the Perfomance tips documents - None of the variables in the train function seem to have type instabilities\n",
    "        . For example in the perfomance tips they have a variable y that was the Union{Int64, Float 64} which would be type instable. But based on this variable list for train function\n",
    "#unused#::#kw##train\n",
    "#temp#@_2::Array{Any,1} ::#train model::Array{Any,1} sequence::Array{Array{Int64,1},1} optim::Array{Knet.Adam,1} S::Int64\n",
    "#temp#@_8::Int64\n",
    "#temp#@_9::Int64\n",
    "#temp#@_10::Any\n",
    "#temp#@_11::Int64 pdrop::Any\n",
    "\n",
    "I also verified the code_warntype for the gneerate function here is the summary\n",
    "\n",
    "Variables:\n",
    "  #self#::#generate\n",
    "  model::Array{Any,1}\n",
    "  tok2int::Dict{Char,Int64}\n",
    "  nchar::Int64\n",
    "  k::Char\n",
    "  v::Int64\n",
    "  #temp#@_7::Int64\n",
    "  #temp#@_8::Int64\n",
    "  t::Int64\n",
    "  embed::Any\n",
    "  #temp#@_11::Int64\n",
    "  ypred::Any\n",
    "  #temp#@_13::Int64\n",
    "  int2tok::Array{Char,1}\n",
    "  input::Any\n",
    "  state::Array{Any,1}\n",
    "  i::Int64\n",
    "  index::Int64\n",
    "  #temp#@_19::Int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find rest of the results for code_warntype - in the LSTM_code_warntype.txt. Conclusion : I didn't find any code instabilities that i needed to fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 ) Profiling the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mThere were no samples collected. Run your program longer (perhaps by\n",
      "running it multiple times), or adjust the delay between samples with\n",
      "Profile.init().\u001b[39m\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mNothing to view\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mNothing to view\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1mprepare_data\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{UInt64,1}, ::Dict{UInt64,Array{StackFrame,1}}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/manvithaponnapati/.julia/v0.6/ProfileView/src/ProfileView.jl:76\u001b[22m\u001b[22m",
      " [2] \u001b[1m#prepare#2\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Bool, ::Dict{UInt64,Array{StackFrame,1}}, ::Bool, ::Bool, ::Array{Any,1}, ::Function, ::Array{UInt64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/manvithaponnapati/.julia/v0.6/ProfileView/src/ProfileView.jl:68\u001b[22m\u001b[22m",
      " [3] \u001b[1m(::ProfileView.#kw##prepare)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::ProfileView.#prepare, ::Array{UInt64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m",
      " [4] \u001b[1m#view#1\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Bool, ::Dict{UInt64,Array{StackFrame,1}}, ::Bool, ::Int64, ::Bool, ::Array{Any,1}, ::Function, ::Array{UInt64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/manvithaponnapati/.julia/v0.6/ProfileView/src/ProfileViewSVG.jl:10\u001b[22m\u001b[22m",
      " [5] \u001b[1m(::ProfileViewSVG.#kw##view)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::ProfileViewSVG.#view, ::Array{UInt64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m (repeats 2 times)",
      " [6] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "using ProfileView\n",
    "f = open(\"cpu_profile.bin\")\n",
    "r = deserialize(f);\n",
    "ProfileView.view(r[1], lidict=r[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Analysis\n",
    "\n",
    "- The most problematic color - RED - mostly seems to arise from the unfuse.jl library. The next ones are backward_pass in core.jl.\n",
    "- Based on the length of the strips - most of the time in my code seems to have been spent in the loss and predict sections of the training function = which definitely makes sense\n",
    "- Each LSTM calculation seems right. Because most of my gate calculations shouldn't take that long anyway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "CPU vs GPU\n",
    "\n",
    "Here are some Epoch results from training on GPU on AWS :\n",
    "\n",
    "(:epoch, 0, :loss, 4.3178406f0)\n",
    "  5.653050 seconds (2.62 M allocations: 114.479 MiB, 0.62% gc time)\n",
    "(:epoch, 1, :loss, 6.149815f0)\n",
    "  1.488483 seconds (1.30 M allocations: 47.919 MiB, 0.78% gc time)\n",
    "(:epoch, 2, :loss, 16.04837f0)\n",
    "  1.161822 seconds (1.21 M allocations: 45.191 MiB, 0.98% gc time)\n",
    "(:epoch, 3, :loss, 17.054678f0)\n",
    "  0.999926 seconds (1.17 M allocations: 43.193 MiB, 1.05% gc time)\n",
    "(:epoch, 4, :loss, 15.71337f0)\n",
    "  0.934595 seconds (1.18 M allocations: 41.958 MiB, 1.08% gc time)\n",
    "(:epoch, 5, :loss, 14.648461f0)\n",
    "  0.901453 seconds (1.20 M allocations: 42.107 MiB, 1.13% gc time)\n",
    "(:epoch, 6, :loss, 13.888727f0)\n",
    "  0.910199 seconds (1.22 M allocations: 42.244 MiB, 1.05% gc time)\n",
    "(:epoch, 7, :loss, 12.295269f0)\n",
    "  0.904278 seconds (1.24 M allocations: 42.083 MiB, 1.10% gc time)\n",
    "(:epoch, 8, :loss, 10.94912f0)\n",
    "  0.967196 seconds (1.20 M allocations: 41.275 MiB, 0.51% gc time)\n",
    "(:epoch, 9, :loss, 9.442087f0)\n",
    "  0.885926 seconds (1.25 M allocations: 41.912 MiB, 1.08% gc time)\n",
    "(:epoch, 10, :loss, 8.839104f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# GPU Epoch Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(:epoch, 0, :loss, 4.3178406f0)\n",
    "  5.653050 seconds (2.62 M allocations: 114.479 MiB, 0.62% gc time)\n",
    "  \n",
    "  \n",
    "(:epoch, 1, :loss, 6.149815f0)\n",
    "  1.488483 seconds (1.30 M allocations: 47.919 MiB, 0.78% gc time)\n",
    "  \n",
    "  \n",
    "(:epoch, 2, :loss, 16.04837f0)\n",
    "  1.161822 seconds (1.21 M allocations: 45.191 MiB, 0.98% gc time)\n",
    "  \n",
    "(:epoch, 3, :loss, 17.054678f0)\n",
    "  0.999926 seconds (1.17 M allocations: 43.193 MiB, 1.05% gc time)\n",
    "  \n",
    "(:epoch, 4, :loss, 15.71337f0)\n",
    "  0.934595 seconds (1.18 M allocations: 41.958 MiB, 1.08% gc time)\n",
    "  \n",
    "(:epoch, 5, :loss, 14.648461f0)\n",
    "  0.901453 seconds (1.20 M allocations: 42.107 MiB, 1.13% gc time)\n",
    "(:epoch, 6, :loss, 13.888727f0)\n",
    "\n",
    "  0.910199 seconds (1.22 M allocations: 42.244 MiB, 1.05% gc time)\n",
    "(:epoch, 7, :loss, 12.295269f0)\n",
    "\n",
    "  0.904278 seconds (1.24 M allocations: 42.083 MiB, 1.10% gc time)\n",
    "(:epoch, 8, :loss, 10.94912f0)\n",
    "\n",
    "  0.967196 seconds (1.20 M allocations: 41.275 MiB, 0.51% gc time)\n",
    "(:epoch, 9, :loss, 9.442087f0)\n",
    "\n",
    "  0.885926 seconds (1.25 M allocations: 41.912 MiB, 1.08% gc time)\n",
    "(:epoch, 10, :loss, 8.839104f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CPU Epoch Information\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
